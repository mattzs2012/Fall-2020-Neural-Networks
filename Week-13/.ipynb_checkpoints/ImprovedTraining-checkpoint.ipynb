{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Training\n",
    "\n",
    "This week, we investigate some useful methods for improving the performance of neural nets by ensemble methods, where we train several nets on the same datapoints and allow them to \"vote\" on the correct classification or regression prediction. Another helpful approach is to monitor training carefully. Lastly, we will speeding up training with transfer learning, where we start with pre-trained models and try to specialize them for our datasets.\n",
    "\n",
    "## Ensemble Methods\n",
    "\n",
    "A common technique used with classification methods (both non-neural and neural) is to take an ensemble of models and combine them to make classification decisions. For example, we could run 5 neural nets, each with comparable accuracy overall, and classify each datapoint based on the majority vote of the 5 networks.\n",
    "\n",
    "This almost always improves results compared to using just one net because different nets have unique talents and may make errors on different datapoints, but, assuming all the nets have good accuracy, they are typically correct, so these mistakes are frequently restricted to just a minority of models.\n",
    "\n",
    "Let's bring in a few (mini) modern CNN achitectures we wrote in the past to use for some ensembling. Note that any architecture would work for the forthcoming experiments, but the following nets can run relatively quickly.\n",
    "\n",
    "First, we import some things we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic packages\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# keras functions\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MiniVGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for a mini version of VGGNet (Simonyan and Zisserman, 2015)\n",
    "class MiniVGGNet:\n",
    "    def build(height, width, depth, classes):\n",
    "        # create the model and name it MiniVGGNet\n",
    "        model = Sequential(name = 'MiniVGGNet')\n",
    "                \n",
    "        # convolutional layer with 32 3x3 feature maps\n",
    "        model.add(Conv2D(32, (3, 3), padding = 'same', input_shape = (height, width, depth)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        # convolutional layer with 32 3x3 feature maps\n",
    "        model.add(Conv2D(32, (3, 3), padding = 'same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        # 2x2 max pooling layer with stride 2x2\n",
    "        model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        # convolutional layer with 64 3x3 feature maps\n",
    "        model.add(Conv2D(64, (3, 3), padding = 'same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        # convolutional layer with 64 3x3 feature maps\n",
    "        model.add(Conv2D(64, (3, 3), padding = 'same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        # 2x2 max pooling layer with stride 2x2\n",
    "        model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        # flatten the activations from a square to a vector\n",
    "        model.add(Flatten())\n",
    "        \n",
    "        # fully-connected layer\n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        # fully-connected layer with softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation('softmax'))\n",
    "        \n",
    "        # return the model\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MiniGoogLeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniGoogLeNet:\n",
    "    def convolution_module(x, K, kX, kY, stride, channelsDim, padding=\"same\"):\n",
    "        # create a CONV -> BN -> RELU sequence\n",
    "        x = Conv2D(K, (kX, kY), strides = stride, padding = padding)(x)\n",
    "        x = BatchNormalization(axis = channelsDim)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        \n",
    "        # return the output\n",
    "        return x\n",
    "    \n",
    "    def inception_module(x, numberOf1x1Kernels, numberOf3x3Kernels, channelsDim):\n",
    "        # define two \"parallel\" convolutions of size 1x1 and 3x3 concatenated across the channels dimension\n",
    "        convolution_1x1 = MiniGoogLeNet.convolution_module(x, numberOf1x1Kernels, 1, 1, (1, 1), channelsDim)\n",
    "        convolution_3x3 = MiniGoogLeNet.convolution_module(x, numberOf3x3Kernels, 3, 3, (1, 1), channelsDim)\n",
    "        x = concatenate([convolution_1x1, convolution_3x3], axis = channelsDim)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def downsample_module(x, K, channelsDim):\n",
    "        # define a CONV and POOL and then concatenate across the channels dimension\n",
    "        convolution_3x3 = MiniGoogLeNet.convolution_module(x, K, 3, 3, (2, 2), channelsDim, padding = 'valid')\n",
    "        pool = MaxPooling2D((3, 3), strides = (2, 2))(x)\n",
    "        x = concatenate([convolution_3x3, pool], axis = channelsDim)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def build(width, height, depth, classes):\n",
    "        inputShape = (height, width, depth)\n",
    "        channelsDim = -1\n",
    "        \n",
    "        if backend.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "            channelsDim = 1\n",
    "        \n",
    "        # define the model input and first CONV module\n",
    "        inputs = Input(shape = inputShape)\n",
    "        x = MiniGoogLeNet.convolution_module(inputs, 96, 3, 3, (1, 1), channelsDim)\n",
    "        \n",
    "        # two inception modules followed by a downsample module\n",
    "        x = MiniGoogLeNet.inception_module(x, 32, 32, channelsDim)\n",
    "        x = MiniGoogLeNet.inception_module(x, 32, 48, channelsDim)\n",
    "        x = MiniGoogLeNet.downsample_module(x, 80, channelsDim)\n",
    "        \n",
    "        # four inception modules followed by a downsample module\n",
    "        x = MiniGoogLeNet.inception_module(x, 112, 48, channelsDim)\n",
    "        x = MiniGoogLeNet.inception_module(x, 96, 64, channelsDim)\n",
    "        x = MiniGoogLeNet.inception_module(x, 80, 80, channelsDim)\n",
    "        x = MiniGoogLeNet.inception_module(x, 48, 96, channelsDim)\n",
    "        x = MiniGoogLeNet.downsample_module(x, 96, channelsDim)\n",
    "        \n",
    "        # two inception modules followed by global POOL and dropout\n",
    "        x = MiniGoogLeNet.inception_module(x, 176, 160, channelsDim)\n",
    "        x = MiniGoogLeNet.inception_module(x, 176, 160, channelsDim)\n",
    "        x = AveragePooling2D((7, 7))(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        \n",
    "        # softmax classifier\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(classes)(x)\n",
    "        x = Activation('softmax')(x)\n",
    "        \n",
    "        # create a model\n",
    "        model = Model(inputs, x, name='MiniGoogLeNet')\n",
    "        \n",
    "        # return the model\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet:\n",
    "    def residual_module(data, K, stride, channelsDim, reduce = False, reg = 0.0001, bnEpsilon = 0.00002, bnMomentum = 0.9):\n",
    "        shortcut = data\n",
    "        \n",
    "        # 1x1 CONVs\n",
    "        bn1 = BatchNormalization(axis = channelsDim, epsilon = bnEpsilon, momentum = bnMomentum)(data)\n",
    "        act1 = Activation('relu')(bn1)\n",
    "        conv1 = Conv2D(int(K * 0.25), (1, 1), use_bias = False, kernel_regularizer = l2(reg))(act1)\n",
    "        \n",
    "        # 3x3 CONVs\n",
    "        bn2 = BatchNormalization(axis = channelsDim, epsilon = bnEpsilon, momentum = bnMomentum)(conv1)\n",
    "        act2 = Activation('relu')(bn2)\n",
    "        conv2 = Conv2D(int(K * 0.25), (3, 3), strides = stride, padding = 'same', use_bias = False, kernel_regularizer = l2(reg))(act2)\n",
    "        \n",
    "        # 1x1 CONVs\n",
    "        bn3 = BatchNormalization(axis = channelsDim, epsilon = bnEpsilon, momentum = bnMomentum)(conv2)\n",
    "        act3 = Activation('relu')(bn3)\n",
    "        conv3 = Conv2D(K, (1, 1), use_bias = False, kernel_regularizer = l2(reg))(act3)\n",
    "        \n",
    "        # if we reduce the spatial size, apply a CONV layer to the shortcut\n",
    "        if reduce:\n",
    "            shortcut = Conv2D(K, (1, 1), strides = stride, use_bias = False, kernel_regularizer = l2(reg))(act1)\n",
    "            \n",
    "        # add the shortcut and the final CONV\n",
    "        x = add([conv3, shortcut])\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def build(width, height, depth, classes, stages, filters, reg = 0.0001, bnEpsilon = 0.00002, bnMomentum = 0.9, dataset='cifar'):\n",
    "        inputShape = (height, width, depth)\n",
    "        channelsDim = -1\n",
    "        \n",
    "        if backend.image_data_format() == 'channels_first':\n",
    "            inputShape = (depth, height, width)\n",
    "            channelsDim = 1\n",
    "            \n",
    "        # set the input and apply BN\n",
    "        inputs = Input(shape = inputShape)\n",
    "        x = BatchNormalization(axis = channelsDim, epsilon = bnEpsilon, momentum = bnMomentum)(inputs)\n",
    "        \n",
    "        if dataset == 'cifar':\n",
    "            # apply a single CONV layer\n",
    "            x = Conv2D(filters[0], (3, 3), use_bias = False, padding = 'same',\n",
    "                       kernel_regularizer = l2(reg))(x)\n",
    "        \n",
    "        # loop over the number of stages\n",
    "        for counter in range(0, len(stages)):\n",
    "            # initialize the stride\n",
    "            if counter == 0:\n",
    "                stride = (1, 1)\n",
    "            else:\n",
    "                stride = (2, 2)\n",
    "                    \n",
    "            # apply a residual module to reduce the spatial dimension of the image volume\n",
    "            x = ResNet.residual_module(x, filters[counter + 1], stride, channelsDim, reduce = True, bnEpsilon = bnEpsilon, bnMomentum = bnMomentum)\n",
    "            \n",
    "            # loop over the number of layers in the current stage\n",
    "            for j in range(0, stages[counter] - 1):\n",
    "                # apply a residual module\n",
    "                x = ResNet.residual_module(x, filters[counter + 1], (1, 1), channelsDim, bnEpsilon = bnEpsilon, bnMomentum = bnMomentum)\n",
    "                    \n",
    "        # apply BN -> ACT -> POOL\n",
    "        x = BatchNormalization(axis = channelsDim, epsilon = bnEpsilon, momentum = bnMomentum)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = AveragePooling2D((8, 8))(x)\n",
    "        \n",
    "        # softmax classifier\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(classes, kernel_regularizer = l2(reg))(x)\n",
    "        x = Activation('softmax')(x)\n",
    "        \n",
    "        # create the model\n",
    "        model = Model(inputs, x, name = 'ResNet')\n",
    "        \n",
    "        # return the model\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Ensembles\n",
    "\n",
    "Now, let's look at some ensembling methods. In the simplest case, we train several nets and average the classifications at the end. If the nets have similar performance, but make mistakes on *different* examples, this approach improves performance in most cases.\n",
    "\n",
    "**Quick GPU Check**: Before we start training models, let's check our GPU resources. If you have a GPU set up to work with TensorFlow, its name will be output and it will be used in training. If not, none will be output and your training will use your CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "numGPUs = len(tf.config.experimental.list_physical_devices('GPU'))\n",
    "\n",
    "print(\"Num GPUs Available: \", numGPUs)\n",
    "\n",
    "if numGPUs > 0:\n",
    "    print(tf.test.gpu_device_name())\n",
    "    print(device_lib.list_local_devices()[1].physical_device_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's train several MiniVGGNets on CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-3f3cb75d0e4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# preprocess data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtrainX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mtestX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mtrainY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# load cifar10 data\n",
    "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "\n",
    "# preprocess data\n",
    "trainX = trainX.astype('float')/255.0\n",
    "testX = testX.astype('float')/255.0\n",
    "trainY = to_categorical(trainY, 10)\n",
    "testY = to_categorical(testY, 10)\n",
    "\n",
    "# create an image generator for data augmentation with random shifting, rotation, and horizontal flips\n",
    "aug = ImageDataGenerator(rotation_range = 10, width_shift_range = 0.1, height_shift_range = 0.1, horizontal_flip = True, fill_mode = 'nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "numberOfModels = 5\n",
    "epochs = 5\n",
    "\n",
    "for i in range(numberOfModels):\n",
    "    print('Net', i, 'is being trained...')\n",
    "    \n",
    "    # choose the optimizer\n",
    "    opt = SGD(lr = 0.01, decay = 0.1 / epochs, momentum = 0.9, nesterov = True)\n",
    "    \n",
    "    # compile the model\n",
    "    model = MiniVGGNet.build(32, 32, 3, 10)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
    "    \n",
    "    # train the model\n",
    "    H = model.fit(aug.flow(trainX, trainY, batch_size = 64), validation_data = (testX, testY), epochs = epochs, steps_per_epoch = len(trainX) // 64, verbose = 1)\n",
    "    \n",
    "    # save the model\n",
    "    p = ['models1', 'model_{}.model'.format(i)]\n",
    "    model.save(os.path.sep.join(p))\n",
    "    \n",
    "    # evaluate the network\n",
    "    predictions = model.predict(testX, batch_size=64)\n",
    "    report = classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=labelNames)\n",
    "    \n",
    "    # save the classification report to file\n",
    "    p = ['output1', 'model_{}.txt'.format(i)]\n",
    "    f = open(os.path.sep.join(p), \"w\")\n",
    "    f.write(report)\n",
    "    f.close()\n",
    "    \n",
    "    # plot the training loss and accuracy\n",
    "    p = ['output1', 'model_{}.png'.format(i)]\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, epochs), H.history['loss'], label = 'train_loss')\n",
    "    plt.plot(np.arange(0, epochs), H.history['val_loss'], label = 'val_loss')\n",
    "    plt.plot(np.arange(0, epochs), H.history['accuracy'], label = 'train_acc')\n",
    "    plt.plot(np.arange(0, epochs), H.history['val_accuracy'], label = 'val_acc')\n",
    "    \n",
    "    # add labels and legend\n",
    "    plt.title('Training Loss and Accuracy for model {}'.format(i))\n",
    "    plt.xlabel('Epoch #')\n",
    "    plt.ylabel('Loss/Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # save graphs\n",
    "    plt.savefig(os.path.sep.join(p))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning (Thursday's Class)\n",
    "\n",
    "Transfer learning is where we take large pre-trained nets, load the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (DL)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
