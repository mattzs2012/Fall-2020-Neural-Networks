{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toward Convolutional Neural Networks\n",
    "\n",
    "This week, we will build toward the next big idea in neural networks: convolutional neural networks (frequently called CNNs or ConvNets). These are nets that take some inspiration from the way neurons are connected in an animal's visual cortex, where different groups of neurons respond to specific portions of the visual field and then those signals are combined in a sort of hierarchy that is thought to allow animals to extract increasingly complex features within the incoming visual stimuli.\n",
    "\n",
    "CNNs are are feedforward neural networks like we have seen, but neurons in one layer are not necessarily connected to every neuron in the next layer. Such a more complex architecture, in some sense, allows a regularized version of fully-connected nets in that, they can generalize better to test data and to the real world. Recall, we could learn the whole training set for CIFAR-10 but had at least a 30% less accuracy on test data. Another benefit is that this more sparse sort of structure means we can build deeper or wider neural nets without growing the computation as much as fully-connected nets.\n",
    "\n",
    "CNNs are some of the best algorithms for image and video recognition problems, but have also been used effectively in anomaly detection, time series analysis in financial markets, and predicting the interactions between proteins and molecules in drug discovery among other applications.\n",
    "\n",
    "Before we get into this, let's take a look at Keras to ensure our computation is as efficient as possible.\n",
    "\n",
    "## Using Keras\n",
    "\n",
    "Since computation is a bottleneck for neural nets, it is worthwhile to learn to construct neural nets with a dedicated deep learning framework rather than simply raw Python with NumPy, as we have used so far, because they allow highly optimized computation accelerated by graphics processing units (GPUs) and let us create nets quickly and easily.\n",
    "\n",
    "As of now, the most popular solutions are probably Facebook's PyTorch and Google's TensorFlow with Keras. (There are some other solutions like Theano, Caffe, and MXNet as well.) Both have two main parts: (1) highly optimized tensor computing, including matrix multiplication and (2) simple functionality for creating neural networks with optimized backpropagation.\n",
    "\n",
    "We only use TensorFlow + Keras in the class, but it is good to know these other options exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing a Fully-connected Feedforward Neural Net with Keras\n",
    "\n",
    "We will aim to write a neural net similar to what we have constructed through the course so far. That is, it should feed data forward through a sequence of layers, the layers should be fully connected (dense), and we should use SGD to optimize it. We can import these things directly from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct the net to classify MNIST (our beloved benchmarking dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 2.2954 - accuracy: 0.1363 - val_loss: 2.2855 - val_accuracy: 0.2202\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 2.2769 - accuracy: 0.1951 - val_loss: 2.2658 - val_accuracy: 0.2321\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 2.2526 - accuracy: 0.3111 - val_loss: 2.2347 - val_accuracy: 0.4171\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 2.2122 - accuracy: 0.4481 - val_loss: 2.1821 - val_accuracy: 0.6217\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 2.1457 - accuracy: 0.5634 - val_loss: 2.0977 - val_accuracy: 0.5981\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 2.0417 - accuracy: 0.6039 - val_loss: 1.9696 - val_accuracy: 0.5775\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 1.8905 - accuracy: 0.6250 - val_loss: 1.7911 - val_accuracy: 0.6311\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 1.6960 - accuracy: 0.6525 - val_loss: 1.5815 - val_accuracy: 0.6783\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 1.4897 - accuracy: 0.6850 - val_loss: 1.3822 - val_accuracy: 0.7009\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 1.3072 - accuracy: 0.7131 - val_loss: 1.2165 - val_accuracy: 0.7395\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 1.1608 - accuracy: 0.7396 - val_loss: 1.0873 - val_accuracy: 0.7547\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 1.0459 - accuracy: 0.7595 - val_loss: 0.9851 - val_accuracy: 0.7695\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.9537 - accuracy: 0.7776 - val_loss: 0.9019 - val_accuracy: 0.7895\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.8777 - accuracy: 0.7918 - val_loss: 0.8313 - val_accuracy: 0.8033\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.8133 - accuracy: 0.8049 - val_loss: 0.7713 - val_accuracy: 0.8185\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.7583 - accuracy: 0.8156 - val_loss: 0.7196 - val_accuracy: 0.8250\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.7109 - accuracy: 0.8251 - val_loss: 0.6760 - val_accuracy: 0.8296\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.6700 - accuracy: 0.8334 - val_loss: 0.6370 - val_accuracy: 0.8388\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.6346 - accuracy: 0.8405 - val_loss: 0.6033 - val_accuracy: 0.8482\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.6040 - accuracy: 0.8468 - val_loss: 0.5743 - val_accuracy: 0.8543\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.5772 - accuracy: 0.8529 - val_loss: 0.5495 - val_accuracy: 0.8604\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.5538 - accuracy: 0.8574 - val_loss: 0.5265 - val_accuracy: 0.8645\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.5333 - accuracy: 0.8622 - val_loss: 0.5077 - val_accuracy: 0.8702\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.5151 - accuracy: 0.8662 - val_loss: 0.4906 - val_accuracy: 0.8725\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.4989 - accuracy: 0.8691 - val_loss: 0.4746 - val_accuracy: 0.8768\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.4844 - accuracy: 0.8724 - val_loss: 0.4611 - val_accuracy: 0.8784\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.4713 - accuracy: 0.8755 - val_loss: 0.4487 - val_accuracy: 0.8819\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.4596 - accuracy: 0.8784 - val_loss: 0.4379 - val_accuracy: 0.8842\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.4489 - accuracy: 0.8802 - val_loss: 0.4278 - val_accuracy: 0.8854\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.4393 - accuracy: 0.8822 - val_loss: 0.4183 - val_accuracy: 0.8877\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.4304 - accuracy: 0.8841 - val_loss: 0.4107 - val_accuracy: 0.8901\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4224 - accuracy: 0.8861 - val_loss: 0.4023 - val_accuracy: 0.8913\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.4149 - accuracy: 0.8872 - val_loss: 0.3953 - val_accuracy: 0.8931\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.4082 - accuracy: 0.8887 - val_loss: 0.3890 - val_accuracy: 0.8945\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.4018 - accuracy: 0.8903 - val_loss: 0.3834 - val_accuracy: 0.8956\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3960 - accuracy: 0.8915 - val_loss: 0.3778 - val_accuracy: 0.8964\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3905 - accuracy: 0.8926 - val_loss: 0.3726 - val_accuracy: 0.8975\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3853 - accuracy: 0.8937 - val_loss: 0.3688 - val_accuracy: 0.8983\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3808 - accuracy: 0.8948 - val_loss: 0.3636 - val_accuracy: 0.8973\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.3763 - accuracy: 0.8960 - val_loss: 0.3594 - val_accuracy: 0.9010\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3721 - accuracy: 0.8968 - val_loss: 0.3558 - val_accuracy: 0.9000\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.3681 - accuracy: 0.8974 - val_loss: 0.3516 - val_accuracy: 0.9008\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3644 - accuracy: 0.8985 - val_loss: 0.3482 - val_accuracy: 0.9018\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.3609 - accuracy: 0.8992 - val_loss: 0.3449 - val_accuracy: 0.9042\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3574 - accuracy: 0.9002 - val_loss: 0.3428 - val_accuracy: 0.9031\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3543 - accuracy: 0.9007 - val_loss: 0.3393 - val_accuracy: 0.9031\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.3512 - accuracy: 0.9011 - val_loss: 0.3364 - val_accuracy: 0.9043\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3483 - accuracy: 0.9017 - val_loss: 0.3337 - val_accuracy: 0.9045\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3456 - accuracy: 0.9028 - val_loss: 0.3312 - val_accuracy: 0.9054\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3429 - accuracy: 0.9032 - val_loss: 0.3286 - val_accuracy: 0.9066\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3403 - accuracy: 0.9039 - val_loss: 0.3261 - val_accuracy: 0.9066\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3378 - accuracy: 0.9044 - val_loss: 0.3243 - val_accuracy: 0.9066\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3356 - accuracy: 0.9047 - val_loss: 0.3217 - val_accuracy: 0.9065\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3331 - accuracy: 0.9056 - val_loss: 0.3194 - val_accuracy: 0.9075\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3310 - accuracy: 0.9059 - val_loss: 0.3179 - val_accuracy: 0.9084\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.3289 - accuracy: 0.9062 - val_loss: 0.3156 - val_accuracy: 0.9088\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3268 - accuracy: 0.9066 - val_loss: 0.3138 - val_accuracy: 0.9087\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3248 - accuracy: 0.9074 - val_loss: 0.3116 - val_accuracy: 0.9102\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3229 - accuracy: 0.9079 - val_loss: 0.3105 - val_accuracy: 0.9109\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.3210 - accuracy: 0.9084 - val_loss: 0.3084 - val_accuracy: 0.9104\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3192 - accuracy: 0.9088 - val_loss: 0.3074 - val_accuracy: 0.9112\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.3175 - accuracy: 0.9096 - val_loss: 0.3055 - val_accuracy: 0.9118\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3157 - accuracy: 0.9099 - val_loss: 0.3036 - val_accuracy: 0.9117\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3140 - accuracy: 0.9104 - val_loss: 0.3021 - val_accuracy: 0.9125\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3124 - accuracy: 0.9110 - val_loss: 0.3009 - val_accuracy: 0.9132\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3108 - accuracy: 0.9114 - val_loss: 0.2992 - val_accuracy: 0.9133\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3092 - accuracy: 0.9113 - val_loss: 0.2982 - val_accuracy: 0.9143\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3078 - accuracy: 0.9124 - val_loss: 0.2967 - val_accuracy: 0.9135\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3063 - accuracy: 0.9123 - val_loss: 0.2951 - val_accuracy: 0.9140\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3049 - accuracy: 0.9126 - val_loss: 0.2937 - val_accuracy: 0.9159\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3034 - accuracy: 0.9128 - val_loss: 0.2927 - val_accuracy: 0.9152\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3020 - accuracy: 0.9133 - val_loss: 0.2914 - val_accuracy: 0.9161\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3007 - accuracy: 0.9136 - val_loss: 0.2904 - val_accuracy: 0.9159\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2995 - accuracy: 0.9136 - val_loss: 0.2891 - val_accuracy: 0.9166\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2981 - accuracy: 0.9143 - val_loss: 0.2879 - val_accuracy: 0.9173\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2968 - accuracy: 0.9145 - val_loss: 0.2869 - val_accuracy: 0.9167\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2955 - accuracy: 0.9151 - val_loss: 0.2855 - val_accuracy: 0.9173\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2944 - accuracy: 0.9150 - val_loss: 0.2844 - val_accuracy: 0.9182\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2932 - accuracy: 0.9150 - val_loss: 0.2835 - val_accuracy: 0.9185\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2920 - accuracy: 0.9156 - val_loss: 0.2823 - val_accuracy: 0.9177\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2908 - accuracy: 0.9158 - val_loss: 0.2816 - val_accuracy: 0.9186\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2898 - accuracy: 0.9164 - val_loss: 0.2807 - val_accuracy: 0.9185\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2886 - accuracy: 0.9162 - val_loss: 0.2794 - val_accuracy: 0.9191\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2874 - accuracy: 0.9168 - val_loss: 0.2785 - val_accuracy: 0.9192\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2864 - accuracy: 0.9170 - val_loss: 0.2778 - val_accuracy: 0.9190\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2853 - accuracy: 0.9172 - val_loss: 0.2765 - val_accuracy: 0.9197\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2842 - accuracy: 0.9179 - val_loss: 0.2757 - val_accuracy: 0.9201\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2832 - accuracy: 0.9178 - val_loss: 0.2746 - val_accuracy: 0.9201\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2822 - accuracy: 0.9180 - val_loss: 0.2740 - val_accuracy: 0.9209\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2811 - accuracy: 0.9183 - val_loss: 0.2732 - val_accuracy: 0.9201\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2801 - accuracy: 0.9184 - val_loss: 0.2721 - val_accuracy: 0.9204\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2793 - accuracy: 0.9186 - val_loss: 0.2710 - val_accuracy: 0.9208\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2783 - accuracy: 0.9185 - val_loss: 0.2704 - val_accuracy: 0.9214\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2772 - accuracy: 0.9191 - val_loss: 0.2697 - val_accuracy: 0.9211\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2763 - accuracy: 0.9194 - val_loss: 0.2685 - val_accuracy: 0.9215\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2753 - accuracy: 0.9196 - val_loss: 0.2679 - val_accuracy: 0.9221\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2746 - accuracy: 0.9201 - val_loss: 0.2670 - val_accuracy: 0.9222\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2735 - accuracy: 0.9204 - val_loss: 0.2663 - val_accuracy: 0.9218\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2726 - accuracy: 0.9204 - val_loss: 0.2659 - val_accuracy: 0.9221\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2718 - accuracy: 0.9208 - val_loss: 0.2649 - val_accuracy: 0.9222\n",
      "Validation accuracy\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       980\n",
      "           1       0.97      0.98      0.97      1135\n",
      "           2       0.92      0.90      0.91      1032\n",
      "           3       0.90      0.91      0.91      1010\n",
      "           4       0.92      0.93      0.93       982\n",
      "           5       0.90      0.87      0.88       892\n",
      "           6       0.93      0.95      0.94       958\n",
      "           7       0.93      0.92      0.93      1028\n",
      "           8       0.89      0.88      0.89       974\n",
      "           9       0.90      0.90      0.90      1009\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22933b5e908>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a feedforward neural net\n",
    "model = Sequential()\n",
    "\n",
    "# Create the first hidden layer\n",
    "model.add(Dense(256, input_shape = (784,), activation = \"sigmoid\"))\n",
    "\n",
    "# Create the second hidden layer\n",
    "model.add(Dense(128, activation = \"sigmoid\"))\n",
    "\n",
    "# Create the output layer\n",
    "model.add(Dense(10, activation = \"sigmoid\"))\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = SGD(0.01), metrics = [\"accuracy\"])\n",
    "\n",
    "### CLASSIFY MNIST PICTURES\n",
    "\n",
    "# create a dataset of 1000 MNIST images, reshaped as single vectors, and labels\n",
    "\n",
    "((trainX, trainY), (testX, testY)) = mnist.load_data()\n",
    "\n",
    "trainX = trainX.reshape((trainX.shape[0], 28 * 28 * 1))\n",
    "testX = testX.reshape((testX.shape[0], 28 * 28 * 1))\n",
    "\n",
    "trainX = trainX/255.0\n",
    "testX = testX/255.0\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "# fit the model to the training data\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY), epochs = 100, batch_size = 128)\n",
    "\n",
    "print(\"Validation accuracy\")\n",
    "testY = LabelBinarizer().fit_transform(testY)\n",
    "predictedY = model.predict(testX, batch_size = 128)\n",
    "predictedY = predictedY.argmax(axis=1)\n",
    "testY = testY.argmax(axis=1)\n",
    "\n",
    "print(classification_report(testY, predictedY))\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, 100), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, 100), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, 100), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, 100), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 30s 600us/sample - loss: 2.7709 - accuracy: 0.1540 - val_loss: 2.1235 - val_accuracy: 0.1339\n",
      "Epoch 2/100\n",
      " 6208/50000 [==>...........................] - ETA: 23s - loss: 2.2743 - accuracy: 0.1324"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-7bf772fa8fc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[INFO] training network...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"categorical_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m# evaluate the network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load the training and testing data, scale it into the range [0, 1],\n",
    "# then reshape the design matrix\n",
    "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "\n",
    "trainX = trainX/255.0\n",
    "testX = testX/255.0\n",
    "\n",
    "trainX = trainX.reshape((trainX.shape[0], 3072))\n",
    "testX = testX.reshape((testX.shape[0], 3072))\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "# initialize the label names for the CIFAR-10 dataset\n",
    "labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "# define the 3072-1024-512-10 architecture using Keras\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(3072,), activation=\"relu\"))\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"relu\"))\n",
    "\n",
    "# train the model using SGD\n",
    "print(\"[INFO] training network...\")\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer = SGD(0.01), metrics = [\"accuracy\"])\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY), epochs = 100, batch_size = 32)\n",
    "\n",
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=labelNames))\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, 100), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, 100), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, 100), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, 100), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (DL)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
